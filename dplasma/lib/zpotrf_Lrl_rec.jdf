extern "C" %{
/*
 *  Copyright (c) 2010-2012
 *
 *  The University of Tennessee and The University
 *  of Tennessee Research Foundation.  All rights
 *  reserved.
 *
 * @precisions normal z -> s d c
 *
 */
#define PRECISION_z

#include <plasma.h>
#include <core_blas.h>

#include "dague.h"
#include "data_distribution.h"
#include "data_dist/matrix/precision.h"
#include "data_dist/matrix/matrix.h"
#include "dplasma/lib/memory_pool.h"
#include "dplasma/lib/dplasmajdf.h"

#include "data_dist/matrix/local_rectangle_cyclic.h"
#include "data_dist/matrix/two_dim_rectangle_cyclic.h"
#include "data_dist/matrix/sym_two_dim_rectangle_cyclic.h"
#include "dplasma.h"

#if defined(HAVE_CUDA)
#include <dague/devices/cuda/dev_cuda.h>
#include "dplasma/cores/cuda_zgemm.h"
extern int *gpu_counter;
#endif  /* defined(HAVE_CUDA) */

#define RECURSIVE_POTRF
#define RECURSIVE_HERK
#define RECURSIVE_TRSM
//#define RECURSIVE_GEMM

typedef struct cb_data_s {
    dague_execution_unit_t *context;
    dague_execution_context_t *task;
    dague_ddesc_t * A;
    dague_ddesc_t * B;
    dague_ddesc_t * C;
    void (*destruct)( dague_handle_t * );
} cb_data_t;

static int complete_recursive_dague_callback(dague_handle_t* dague_handle, void* cb_data)
{
    int rc = 0;
    cb_data_t* data = (cb_data_t*)cb_data;

    rc = __dague_complete_execution(data->context, data->task);

    if (data->A != NULL) free(data->A);
    if (data->B != NULL) free(data->B);
    if (data->C != NULL) free(data->C);

    data->destruct( dague_handle );
    free(data);
    return rc;
}

%}

/* Globals
 */
PRI_CHANGE [type = int hidden = on]
uplo       [type = PLASMA_enum]
dataA      [type = "dague_ddesc_t *"]
descA      [type = "tiled_matrix_desc_t" hidden = on default = "*((tiled_matrix_desc_t*)dataA)"]
INFO       [type = "int*"]
smallnb    [type = "int" hidden=on default="(192)" ]

/**************************************************
 *                      POTRF                     *
 **************************************************/
POTRF(k) [high_priority = on]

// Execution space
k = 0..descA.mt-1

// Parallel partitioning
:dataA(k, k)

// Parameters
RW T <- (k == 0) ? dataA(k, k) : T HERK(k-1, k)
     -> T TRSM(k+1..descA.mt-1, k)
     -> dataA(k, k)

; (k >= (descA.mt - PRI_CHANGE)) ? (descA.mt - k) * (descA.mt - k) * (descA.mt - k) : 1000000000
//; (k >= (descA.mt - PRI_CHANGE)) ? (descA.mt - k + 7) * (descA.mt - k + 2) * (descA.mt - k) / 6 : 0

BODY

    int tempkm = k == descA.mt-1 ? descA.m - k*descA.mb : descA.mb;
    int ldak = BLKLDD( descA, k );

#if !defined(DAGUE_DRY_RUN)
    int iinfo = 0;

#if defined(RECURSIVE_POTRF)
    if (tempkm > smallnb) {
        local_block_cyclic_t *small_descT;
        dague_handle_t *dague_zpotrf;
        cb_data_t      *cbdata_zpotrf;

        small_descT = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        local_block_cyclic_init(small_descT,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldak, tempkm,
                                  0, 0, tempkm, tempkm, 1, 1, 1);
        small_descT->mat = T;

        /* Dague_object */
        dague_zpotrf = dplasma_zpotrf_New(uplo, (tiled_matrix_desc_t *)small_descT, &iinfo );
        dague_zpotrf->devices_mask = 1;
        //((dague_zpotrf_Lrl_object_t*)dague_zpotrf)->smallnb = smallnb;
        //dague_set_priority( dague_zpotrf, 0x7fffffff-1);

        /* Callback */
        cbdata_zpotrf = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_zpotrf->context = context;
        cbdata_zpotrf->task    = this_task;
        cbdata_zpotrf->A       = (dague_ddesc_t *)small_descT;
        cbdata_zpotrf->B       = NULL;
        cbdata_zpotrf->C       = NULL;
        cbdata_zpotrf->destruct= dplasma_zpotrf_Destruct;
        dague_set_complete_callback(dague_zpotrf,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_zpotrf);

        dague_enqueue(context->virtual_process->dague_context, dague_zpotrf);
        return -1;

    }
    else
#endif /* defined(RECURSIVE_POTRF) */
    {

    CORE_zpotrf(uplo, tempkm, T, ldak, &iinfo );
    if( iinfo != 0 && *INFO == 0 )
        *INFO = k*descA.mb+iinfo; /* Should return here */
/*    printf("k %d, info %d\n", k, iinfo);*/
    
    }
#endif  /* !defined(DAGUE_DRY_RUN) */

    printlog("CORE_zpotrf( %d )\n\t( %s, %d, A(%d,%d)[%p], %d)\n",
             k,
             plasma_const(uplo), tempkm, k, k, T, descA.mb );

END


/**************************************************
 *                      TRSM                      *
 **************************************************/
TRSM(m, k) [high_priority = on]

// Execution space
m = 1..descA.mt-1
k = 0..m-1

// Parallel partitioning
: dataA(m, k)

// Parameters
READ  T <- T POTRF(k)
RW    C <- (k == 0) ? dataA(m, k) : C GEMM(k-1, m, k)
        -> A HERK(k, m)
        -> A GEMM(k, m, k+1..m-1 )
        -> B GEMM(k, m+1..descA.mt-1, m )
        -> dataA(m, k)

; (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m) * (descA.mt - m) * (descA.mt - m) + 3 * ((2 * descA.mt) - k - m - 1) * (m - k) : 1000000000
//;  (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m - k) * ((descA.mt - m - k + 1) / 2 + 2) - 1 + (descA.mt - m + 2) * (descA.mt - m + 1) * (descA.mt - m) / 6 : 0

BODY

    int tempmm = m == descA.mt-1 ? descA.m - m * descA.mb : descA.mb;
    int ldak = BLKLDD( descA, k );
    int ldam = BLKLDD( descA, m );
#if !defined(DAGUE_DRY_RUN)

#if defined(RECURSIVE_TRSM)
    if (tempmm > smallnb || descA.nb > smallnb) {
        local_block_cyclic_t *small_descT, *small_descC;
        dague_handle_t* dague_ztrsm;
        cb_data_t  *cbdata_ztrsm;

        small_descT = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        small_descC = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));

        local_block_cyclic_init(small_descT,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldak, descA.nb,
                                  0, 0, descA.nb, descA.nb, 1, 1, 1);
        small_descT->mat = T;
        local_block_cyclic_init(small_descC,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, descA.nb, 1, 1, 1);
        small_descC->mat = C;

        dague_ztrsm = dplasma_ztrsm_New(PlasmaRight, PlasmaLower,
                                        PlasmaConjTrans, PlasmaNonUnit,
                                        (dague_complex64_t)1.0,
                                        (tiled_matrix_desc_t *)small_descT,
                                        (tiled_matrix_desc_t *)small_descC );
        dague_ztrsm->devices_mask = 1;
        //dague_set_priority( dague_ztrsm, 0x7fffffff-2);

        cbdata_ztrsm = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_ztrsm->context = context;
        cbdata_ztrsm->task = this_task;
        cbdata_ztrsm->A = (dague_ddesc_t *) small_descT;
        cbdata_ztrsm->B = (dague_ddesc_t *) small_descC;
        cbdata_ztrsm->C = NULL;
        cbdata_ztrsm->destruct = dplasma_ztrsm_Destruct;
        dague_set_complete_callback(dague_ztrsm,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_ztrsm);

        dague_enqueue(context->virtual_process->dague_context, dague_ztrsm);
        dague_data_transfer_ownership_to_copy(gC->original, 0 /* device */,ACCESS_WRITE);
        return -1;
    }
    else
#endif /* defined(RECURSIVE_TRSM) */
    {
 //   printf("SMALL TRSM\n");
    CORE_ztrsm(PlasmaRight, PlasmaLower, PlasmaConjTrans, PlasmaNonUnit,
               tempmm, descA.nb,
               (dague_complex64_t)1.0, T /*A(k, k)*/, ldak,
                                       C /*A(m, k)*/, ldam);
    }

#endif  /* !defined(DAGUE_DRY_RUN) */
    
/*	printf("[TRSM] m=%d, k=%d\n", m, k);*/
    printlog("CORE_ztrsm( %d, %d )\n\t( %s, %s, %s, %s, %d, %d, %f, A(%d,%d)[%p], %d,  A(%d,%d)[%p], %d)\n",
             m, k,
             plasma_const( PlasmaRight ), plasma_const( PlasmaLower ),
             plasma_const( PlasmaConjTrans ), plasma_const( PlasmaNonUnit ),
             tempmm, descA.nb,
             1.0, k, k, T, ldak,
                  m, k, C, ldam);

END


/**************************************************
 *                      HERK                      *
 **************************************************/
HERK(k, m) [high_priority = on]

// Execution space
k = 0..descA.mt-2
m = k+1..descA.mt-1

// Parallel partitioning
: dataA(m, m)

//Parameters
READ  A <- C TRSM(m, k)
RW    T <- (k == 0)   ? dataA(m, m)    : T HERK(k-1, m)
        -> (m == k+1) ? T POTRF(m) : T HERK(k+1, m)

; (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m) * (descA.mt - m) * (descA.mt - m) + 3 * (m - k) : 1000000000
//; (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m + 2) * (descA.mt - m + 1) * (descA.mt - m) / 6 + descA.mt - m + k + 1 : 0

BODY

    int tempmm = m == descA.mt-1 ? descA.m - m*descA.mb : descA.mb;
    int ldam = BLKLDD( descA, m );

#if !defined(DAGUE_DRY_RUN)
#if defined(RECURSIVE_HERK)
    if (tempmm > smallnb || descA.mb > smallnb) {
        local_block_cyclic_t *small_descT, *small_descA;
        dague_handle_t* dague_zherk;
        cb_data_t  *cbdata_zherk;

        small_descT = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        small_descA = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));

        local_block_cyclic_init(small_descT,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, tempmm, 1, 1, 1);
        small_descT->mat = T;
        local_block_cyclic_init(small_descA,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, descA.nb, 1, 1, 1);
        small_descA->mat = A;

        dague_zherk = dplasma_zherk_New( PlasmaLower, PlasmaNoTrans,
                                         (double)-1.0, (tiled_matrix_desc_t*) small_descA,
                                         (double)1.0,  (tiled_matrix_desc_t*) small_descT);
        dague_zherk->devices_mask = 1;
        //dague_set_priority( dague_zherk, 0x7fffffff-2);

        cbdata_zherk = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_zherk->context = context;
        cbdata_zherk->task = this_task;
        cbdata_zherk->A = (dague_ddesc_t *) small_descA;
        cbdata_zherk->B = (dague_ddesc_t *) small_descT;
        cbdata_zherk->C = NULL;
        cbdata_zherk->destruct = dplasma_zherk_Destruct;
        dague_set_complete_callback(dague_zherk,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_zherk);

        dague_enqueue(context->virtual_process->dague_context, dague_zherk);
        return -1;
    }
    else
#endif /* defined(RECURSIVE_HERK) */
    {

    CORE_zherk(PlasmaLower, PlasmaNoTrans,
               tempmm, descA.mb,
               (double)-1.0, A /*A(m, k)*/, ldam,
               (double) 1.0, T /*A(m, m)*/, ldam);
    }

#endif  /* !defined(DAGUE_DRY_RUN) */

    printlog(
             "CORE_zherk( %d, %d )\n\t( %s, %s, %d, %d, %f, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             k, m,
             plasma_const( PlasmaLower ), plasma_const( PlasmaNoTrans ),
             tempmm, descA.mb,
             -1.0, m, k, A, ldam,
              1.0, m, m, T, ldam);
END

/**************************************************
 *                      GEMM                      *
 **************************************************/
// Name
GEMM(k, m, n) [profile = off]

// Execution space
k = 0   .. descA.mt-3
m = k+2 .. descA.mt-1
n = k+1 .. m-1

// Parallel partitioning
: dataA(m, n)

// Parameters
READ  A <- C TRSM(m, k)
READ  B <- C TRSM(n, k)
RW    C <- (k == 0)   ? dataA(m, n)      : C GEMM(k-1, m, n)
        -> (n == k+1) ? C TRSM(m, n) : C GEMM(k+1, m, n)

; (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m) * (descA.mt - m) * (descA.mt - m) + 3 * ((2 * descA.mt) - m - n - 3) * (m - n) + 6 * (m - k) : 1000000000
//;  (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m - n) * ((descA.mt - n - k + 1) / 2 + 2) - 1 + (descA.mt - m + 2) * (descA.mt - m + 1) * (descA.mt - m) / 6 + descA.mt - n + k + 1 : 0

BODY [type = CUDA]
    int tempmm = m == descA.mt-1 ? descA.m - m * descA.mb : descA.mb;
    int ldam = BLKLDD( descA, m );
    int ldan = BLKLDD( descA, n );

    if (tempmm > smallnb || descA.nb > smallnb) {

        return gpu_zgemm(context, this_task,
                         ( n == k+1 ),
                         PlasmaNoTrans, PlasmaConjTrans,
                         tempmm, descA.mb, descA.mb,
                         (dague_complex64_t)-1.0, m, k, &descA, ldam,
                                                  n, k, &descA, ldan,
                         (dague_complex64_t) 1.0, m, n, &descA, ldam);
    } else {
#if !defined(DAGUE_DRY_RUN)
    CORE_zgemm(PlasmaNoTrans, PlasmaConjTrans,
               tempmm, descA.mb, descA.mb,
               (dague_complex64_t)-1.0, A /*A(m, k)*/, ldam,
                                        B /*A(n, k)*/, ldan,
               (dague_complex64_t) 1.0, C /*A(m, n)*/, ldam);
#endif  /* !defined(DAGUE_DRY_RUN) */
	
    }
END

BODY
    int tempmm = m == descA.mt-1 ? descA.m - m * descA.mb : descA.mb;
    int ldam = BLKLDD( descA, m );
    int ldan = BLKLDD( descA, n );


#if defined(RECURSIVE_GEMM)
    if (tempmm > smallnb || descA.nb > smallnb) {

        //printf("big gemm on CPU\n");

        local_block_cyclic_t *small_descA;
        local_block_cyclic_t *small_descB;
        local_block_cyclic_t *small_descC;
        dague_handle_t *dague_zgemm;
        cb_data_t  *cbdata_zgemm;

        small_descA = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        small_descB = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        small_descC = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));

        local_block_cyclic_init(small_descA,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, tempmm, 1, 1, 1);;
        small_descA->mat = A;
        local_block_cyclic_init(small_descB,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, tempmm, 1, 1, 1);
        small_descB->mat = B;
        local_block_cyclic_init(small_descC,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, tempmm, 1, 1, 1);
        small_descC->mat = C;

        dague_zgemm = dplasma_zgemm_New(PlasmaNoTrans, PlasmaConjTrans,
                                        (dague_complex64_t)-1.0,
                                        (tiled_matrix_desc_t *)small_descA,
                                        (tiled_matrix_desc_t *)small_descB,
                                        (dague_complex64_t) 1.0,
                                        (tiled_matrix_desc_t *)small_descC);
        dague_zgemm->devices_mask = 1;
        //dague_set_priority( dague_zgemm, 0x7fffffff-3);

        cbdata_zgemm = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_zgemm->context = context;
        cbdata_zgemm->task = this_task;
        cbdata_zgemm->A = (dague_ddesc_t *) small_descA;
        cbdata_zgemm->B = (dague_ddesc_t *) small_descB;
        cbdata_zgemm->C = (dague_ddesc_t *) small_descC;
        cbdata_zgemm->destruct = dplasma_zgemm_Destruct;
        dague_set_complete_callback(dague_zgemm,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_zgemm);

        dague_enqueue(context->virtual_process->dague_context, dague_zgemm);
        return -1;
    } else 
#endif /* defined(RECURSIVE_GEMM) */

    {
#if !defined(DAGUE_DRY_RUN)
    CORE_zgemm(PlasmaNoTrans, PlasmaConjTrans,
               tempmm, descA.mb, descA.mb,
               (dague_complex64_t)-1.0, A /*A(m, k)*/, ldam,
                                        B /*A(n, k)*/, ldan,
               (dague_complex64_t) 1.0, C /*A(m, n)*/, ldam);
#endif  /* !defined(DAGUE_DRY_RUN) */
    
    }

    printlog("CORE_zgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %f, A(%d,%d)[%p], %d, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             k, m, n,
             plasma_const( PlasmaNoTrans ),  plasma_const( PlasmaConjTrans ),
             tempmm, descA.mb, descA.mb,
             -1.0, m, k, A, ldam,
                   n, k, B, ldan,
              1.0, m, n, C, ldam);
END
