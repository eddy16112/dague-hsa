extern "C" %{
/*
 * Copyright (c) 2010-2013 The University of Tennessee and The University
 *                         of Tennessee Research Foundation.  All rights
 *                         reserved.
 * Copyright (c) 2013      Inria. All rights reserved.
 *
 * @precisions normal z -> s d c
 *
 */
#include "dplasma/lib/dplasmajdf.h"
#include "data_dist/matrix/matrix.h"
#include "data_dist/matrix/local_rectangle_cyclic.h"
#include "scheduling.h"

#if defined(HAVE_CUDA)
#include <dague/devices/cuda/dev_cuda.h>
#include "dplasma/cores/cuda_zgemm.h"
extern int *gpu_counter;
#endif  /* defined(HAVE_CUDA) */

/*
 * Priorities used in this jdf:
 *      - POTRF(k)    : (MT-k)**3
 *      - HERK(k,n)   : (MT-n)**3 + 3 * (n - k)
 *      - TRSM(n,k)   : (MT-n)**3 + 3 * (n - k) * (2 * MT - k - n - 1)
 *      - GEMM(k,m,n) : (MT-n)**3 + 3 * (n - m) * (2 * MT - m - n - 1) + 6 * (n - k)
 *
 * So max priority is:
 *      (MT - PRI_CHANGE)**3 + 3 * MT * (2 * MT - PRI_CHANGE - 1) + 6 * MT  < (MT**3 + 6 MT**2 + 3 MT)
 *
 * WARNING: If mt is greater than 1200, we might get integer overflow.
 */

#define RECURSIVE_POTRF
#define RECURSIVE_HERK
#define RECURSIVE_TRSM
#define RECURSIVE_GEMM

typedef struct cb_data_s {
    dague_execution_unit_t *context;
    dague_execution_context_t *task;
    dague_ddesc_t * A;
    dague_ddesc_t * B;
    dague_ddesc_t * C;
    void (*destruct)( dague_handle_t * );
} cb_data_t;

static int complete_recursive_dague_callback(dague_handle_t* dague_handle, void* cb_data)
{
    int rc = 0;
    cb_data_t* data = (cb_data_t*)cb_data;

    rc = __dague_complete_execution(data->context, data->task);

    if (data->A != NULL) free(data->A);
    if (data->B != NULL) free(data->B);
    if (data->C != NULL) free(data->C);

    data->destruct( dague_handle );
    free(data);
    return rc;
}

%}

/* Globals
 */
uplo       [type = PLASMA_enum]
dataA      [type = "dague_ddesc_t *"]
INFO       [type = "int*"]

descA      [type = "tiled_matrix_desc_t" hidden = on default = "*((tiled_matrix_desc_t*)dataA)"]
PRI_CHANGE [type = "int" hidden = on default = 0 ]
PRI_MAX    [type = "int" hidden = on default = "(descA.mt * ( 3 + descA.mt * ( 2 + descA.mt )))" ]
smallnb    [type = "int" hidden=on default="(192)" ]

/**************************************************
 *                      POTRF                     *
 **************************************************/
POTRF(k) [high_priority = on]

// Execution space
k = 0 .. descA.nt-1

// Parallel partitioning
:dataA(k, k)

// Parameters
RW T <- (k == 0) ? dataA(k, k) : T HERK(k-1, k)
     -> T TRSM(k, k+1..descA.nt-1)
     -> dataA(k, k)

; (k >= (descA.nt - PRI_CHANGE)) ? (descA.nt - k) * (descA.nt - k) * (descA.nt - k) : PRI_MAX

BODY
{
    int tempkn = k == descA.nt-1 ? descA.n - k*descA.nb : descA.nb;
    int iinfo = 0;
    int ldak = BLKLDD( descA, k );

#if defined(RECURSIVE_POTRF)
    if (tempkn > smallnb) {
        local_block_cyclic_t *small_descT;
        dague_handle_t *dague_zpotrf;
        cb_data_t      *cbdata_zpotrf;

        small_descT = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        local_block_cyclic_init(small_descT,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldak, tempkn,
                                  0, 0, tempkn, tempkn, 1, 1, 1);
        small_descT->mat = T;

        /* Dague_object */
        dague_zpotrf = dplasma_zpotrf_New(uplo, (tiled_matrix_desc_t *)small_descT, &iinfo );
        dague_zpotrf->devices_mask = 1;

        /* Callback */
        cbdata_zpotrf = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_zpotrf->context = context;
        cbdata_zpotrf->task    = this_task;
        cbdata_zpotrf->A       = (dague_ddesc_t *)small_descT;
        cbdata_zpotrf->B       = NULL;
        cbdata_zpotrf->C       = NULL;
        cbdata_zpotrf->destruct= dplasma_zpotrf_Destruct;
        dague_set_complete_callback(dague_zpotrf,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_zpotrf);

        dague_enqueue(context->virtual_process->dague_context, dague_zpotrf);
        return -1;

    }
    else 
#endif /* !defined(RECURSIVE_POTRF) */
    {
#if !defined(DAGUE_DRY_RUN)
    CORE_zpotrf(uplo, tempkn, T, ldak, &iinfo );
    if( iinfo != 0 && *INFO == 0 )
        *INFO = k*descA.nb+iinfo; /* Should return here */
#endif  /* !defined(DAGUE_DRY_RUN) */
    }

    printlog("CORE_zpotrf( %d )\n\t( %s, %d, A(%d,%d)[%p], %d) return info = %d\n",
             k,
             plasma_const(uplo), tempkn, k, k, T, ldak, iinfo );
}
END


/**************************************************
 *                      TRSM                      *
 **************************************************/
TRSM(k, n) [high_priority = on]

// Execution space
k = 0   .. descA.nt-2
n = k+1 .. descA.nt-1

// Parallel partitioning
: dataA(k, n)

// Parameters
READ  T <- T POTRF(k)
RW    C <- (k == 0) ? dataA(k, n) : C GEMM(k-1, k, n)
        -> A HERK(k, n)
        -> A GEMM(k, n, n+1..descA.nt-1)
        -> B GEMM(k, k+1..n-1, n )
        -> dataA(k, n)

; (n >= (descA.nt - PRI_CHANGE)) ? (descA.nt - n) * (descA.nt - n) * (descA.nt - n) + 3 * ((2 * descA.nt) - k - n - 1) * (n - k) : PRI_MAX

BODY
{
    int tempnn = n == descA.nt-1 ? descA.n - n * descA.nb : descA.nb;
    int ldak = BLKLDD( descA, k );

#if defined(RECURSIVE_TRSM)
    if (tempnn > smallnb || descA.mb > smallnb) {
        local_block_cyclic_t *small_descT, *small_descC;
        dague_handle_t* dague_ztrsm;
        cb_data_t  *cbdata_ztrsm;

        small_descT = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        small_descC = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));

        local_block_cyclic_init(small_descT,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldak, descA.mb,
                                  0, 0, descA.mb, descA.mb, 1, 1, 1);
        small_descT->mat = T;
        local_block_cyclic_init(small_descC,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldak, descA.mb,
                                  0, 0, descA.mb, tempnn, 1, 1, 1);
        small_descC->mat = C;

        dague_ztrsm = dplasma_ztrsm_New(PlasmaLeft, PlasmaUpper,
                                        PlasmaConjTrans, PlasmaNonUnit,
                                        (dague_complex64_t)1.0,
                                        (tiled_matrix_desc_t *)small_descT,
                                        (tiled_matrix_desc_t *)small_descC );
        dague_ztrsm->devices_mask = 1;
        //dague_set_priority( dague_ztrsm, 0x7fffffff-2);

        cbdata_ztrsm = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_ztrsm->context = context;
        cbdata_ztrsm->task = this_task;
        cbdata_ztrsm->A = (dague_ddesc_t *) small_descT;
        cbdata_ztrsm->B = (dague_ddesc_t *) small_descC;
        cbdata_ztrsm->C = NULL;
        cbdata_ztrsm->destruct = dplasma_ztrsm_Destruct;
        dague_set_complete_callback(dague_ztrsm,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_ztrsm);

        dague_enqueue(context->virtual_process->dague_context, dague_ztrsm);
        dague_data_transfer_ownership_to_copy(gC->original, 0 /* device */,FLOW_ACCESS_WRITE);
        return -1;

    }
    else
#endif  /* !defined(RECURSIVE_TRSM) */ 

    {

#if !defined(DAGUE_DRY_RUN)
    CORE_ztrsm(PlasmaLeft, PlasmaUpper, PlasmaConjTrans, PlasmaNonUnit,
               descA.mb, tempnn,
               (dague_complex64_t)1.0, T /*A(k, k)*/, ldak,
                                       C /*A(k, n)*/, ldak);
#endif  /* !defined(DAGUE_DRY_RUN) */
    }

    printlog("CORE_ztrsm( %d, %d )\n\t( %s, %s, %s, %s, %d, %d, %f, A(%d,%d)[%p], %d,  A(%d,%d)[%p], %d)\n",
             k, n,
             plasma_const( PlasmaLeft ), plasma_const( PlasmaUpper ),
             plasma_const( PlasmaConjTrans ), plasma_const( PlasmaNonUnit ),
             descA.mb, tempnn,
             1.0, k, k, T, ldak,
                  k, n, C, ldak);
}
END


/**************************************************
 *                      HERK                      *
 **************************************************/
HERK(k, n) [high_priority = on]

// Execution space
k = 0   .. descA.nt-2
n = k+1 .. descA.nt-1

// Parallel partitioning
: dataA(n, n)

//Parameters
READ  A <- C TRSM(k, n)
RW    T <- (k == 0)   ? dataA(n, n) : T HERK(k-1, n)
        -> (n == k+1) ? T POTRF(n)  : T HERK(k+1, n)

; (n >= (descA.nt - PRI_CHANGE)) ? (descA.nt - n) * (descA.nt - n) * (descA.nt - n) + 3 * (n - k) : PRI_MAX

BODY
{
    int tempnn = n == descA.nt-1 ? descA.n - n*descA.nb : descA.nb;
    int ldak = BLKLDD( descA, k );
    int ldan = BLKLDD( descA, n );

#if defined(RECURSIVE_HERK)
    if (tempnn > smallnb || descA.mb > smallnb) {
        local_block_cyclic_t *small_descT, *small_descA;
        dague_handle_t* dague_zherk;
        cb_data_t  *cbdata_zherk;

        small_descT = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        small_descA = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));

        local_block_cyclic_init(small_descT,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldan, descA.mb,
                                  0, 0, tempnn, tempnn, 1, 1, 1);
        small_descT->mat = T;
        local_block_cyclic_init(small_descA,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, context->virtual_process->dague_context->my_rank,
                                  smallnb, smallnb, ldan, descA.mb,
                                  0, 0, descA.mb, tempnn, 1, 1, 1);
        small_descA->mat = A;

        dague_zherk = dplasma_zherk_New( PlasmaUpper, PlasmaConjTrans,
                                         (double)-1.0, (tiled_matrix_desc_t*) small_descA,
                                         (double)1.0,  (tiled_matrix_desc_t*) small_descT);
        dague_zherk->devices_mask = 1;
        //dague_set_priority( dague_zherk, 0x7fffffff-2);

        cbdata_zherk = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_zherk->context = context;
        cbdata_zherk->task = this_task;
        cbdata_zherk->A = (dague_ddesc_t *) small_descA;
        cbdata_zherk->B = (dague_ddesc_t *) small_descT;
        cbdata_zherk->C = NULL;
        cbdata_zherk->destruct = dplasma_zherk_Destruct;
        dague_set_complete_callback(dague_zherk,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_zherk);

        dague_enqueue(context->virtual_process->dague_context, dague_zherk);
        return -1;
    }
    else 
#endif /* !defined(RECURSIVE_HERK) */
    {

#if !defined(DAGUE_DRY_RUN)
    CORE_zherk(PlasmaUpper, PlasmaConjTrans,
               tempnn, descA.mb,
               (double)-1.0, A /*A(k, n)*/, ldak,
               (double) 1.0, T /*A(n, n)*/, ldan);
#endif /* !defined(DAGUE_DRY_RUN) */
    }

    printlog(
             "CORE_zherk( %d, %d )\n\t( %s, %s, %d, %d, %f, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             k, n,
             plasma_const( PlasmaUpper ), plasma_const( PlasmaConjTrans ),
             tempnn, descA.mb,
             -1.0, k, n, A, ldak,
              1.0, n, n, T, ldan);
}
END

/**************************************************
 *                      GEMM                      *
 **************************************************/
// Name
GEMM(k, m, n)

// Execution space
k = 0   .. descA.mt-3
m = k+1 .. descA.mt-1
n = m+1 .. descA.nt-1

// Parallel partitioning
: dataA(m, n)

// Parameters
READ  A <- C TRSM(k, m)
READ  B <- C TRSM(k, n)
RW    C <- (k == 0)   ? dataA(m, n)      : C GEMM(k-1, m, n)
        -> (m == k+1) ? C TRSM(m, n) : C GEMM(k+1, m, n)

; (n >= (descA.nt - PRI_CHANGE)) ? (descA.nt - n) * (descA.nt - n) * (descA.nt - n) + 3 * ((2 * descA.nt) - m - n - 3) * (n - m) + 6 * (n - k) : PRI_MAX

BODY [type=CUDA dyld=cublasZgemm]
{
    int tempnn = n == descA.nt-1 ? descA.n - n * descA.nb : descA.nb;
    int ldak = BLKLDD( descA, k );
    int ldam = BLKLDD( descA, m );

    if (tempnn > smallnb || descA.nb > smallnb) {

        int ret = gpu_zgemm(context, this_task,
                         ( m == k+1 ),
                         PlasmaConjTrans, PlasmaNoTrans,
                         descA.mb, tempnn, descA.nb,
                         (dague_complex64_t)-1.0, k, m, &descA, ldak,
                                                  k, n, &descA, ldak,
                         (dague_complex64_t) 1.0, m, n, &descA, ldam);

        printlog("CUDA_zgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %f, A(%d,%d)[%p], %d, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
                 k, m, n,
                 plasma_const( PlasmaConjTrans ),  plasma_const( PlasmaNoTrans ),
                 descA.mb, tempnn, descA.mb,
                 -1.0, k, m, A, ldak,
                       k, n, B, ldak,
                  1.0, m, n, C, ldam);
        return ret;
    } else {
#if !defined(DAGUE_DRY_RUN)
        CORE_zgemm(PlasmaConjTrans, PlasmaNoTrans,
                   descA.mb, tempnn, descA.nb,
                   (dague_complex64_t)-1.0, A /*A(k, m)*/, ldak,
                                            B /*A(k, n)*/, ldak,
                   (dague_complex64_t) 1.0, C /*A(m, n)*/, ldam);
#endif  /* !defined(DAGUE_DRY_RUN) */

        printlog("CORE_zgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %e, A(%d,%d)[%p], %d, A(%d,%d)[%p], %d, %e, A(%d,%d)[%p], %d)\n",
                 k, m, n,
                 plasma_const( PlasmaConjTrans ),  plasma_const( PlasmaNoTrans ),
                 descA.mb, tempnn, descA.nb,
                 -1.0, k, m, A, ldak,
                       k, n, B, ldak,
                  1.0, m, n, C, ldam);
    }
}
END

BODY
{
    int tempnn = n == descA.nt-1 ? descA.n - n * descA.nb : descA.nb;
    int ldak = BLKLDD( descA, k );
    int ldam = BLKLDD( descA, m );

    #if defined(RECURSIVE_GEMM)
    if (tempnn > smallnb || descA.nb > smallnb) {

        // printf("big gemm on CPU\n");

        local_block_cyclic_t *small_descA;
        local_block_cyclic_t *small_descB;
        local_block_cyclic_t *small_descC;
        dague_handle_t *dague_zgemm;
        cb_data_t  *cbdata_zgemm;

        small_descA = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        small_descB = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));
        small_descC = (local_block_cyclic_t *) malloc(sizeof(local_block_cyclic_t));

        local_block_cyclic_init(small_descA,
                                matrix_ComplexDouble, matrix_Lapack,
                                1, context->virtual_process->dague_context->my_rank,
                                smallnb, smallnb, ldak, descA.nb,
                                0, 0, descA.nb, descA.mb, 1, 1, 1);
        small_descA->mat = A;
        local_block_cyclic_init(small_descB,
                                matrix_ComplexDouble, matrix_Lapack,
                                1, context->virtual_process->dague_context->my_rank,
                                smallnb, smallnb, ldak, descA.nb,
                                0, 0, descA.nb, tempnn, 1, 1, 1);
        small_descB->mat = B;
        local_block_cyclic_init(small_descC,
                                matrix_ComplexDouble, matrix_Lapack,
                                1, context->virtual_process->dague_context->my_rank,
                                smallnb, smallnb, ldam, descA.nb,
                                0, 0, descA.mb, tempnn, 1, 1, 1);
        small_descC->mat = C;

        dague_zgemm = dplasma_zgemm_New(PlasmaConjTrans, PlasmaNoTrans,
                                        (dague_complex64_t)-1.0,
                                        (tiled_matrix_desc_t *)small_descA,
                                        (tiled_matrix_desc_t *)small_descB,
                                        (dague_complex64_t) 1.0,                                                                                                                                                      (tiled_matrix_desc_t *)small_descC);
        dague_zgemm->devices_mask = 1;
        cbdata_zgemm = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_zgemm->context = context;
        cbdata_zgemm->task = this_task;
        cbdata_zgemm->A = (dague_ddesc_t *) small_descA;
        cbdata_zgemm->B = (dague_ddesc_t *) small_descB;
        cbdata_zgemm->C = (dague_ddesc_t *) small_descC;
        cbdata_zgemm->destruct = dplasma_zgemm_Destruct;
        dague_set_complete_callback(dague_zgemm,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_zgemm);
        
        dague_enqueue(context->virtual_process->dague_context, dague_zgemm);
        return -1;
    } else 
#endif /* defined(RECURSIVE_GEMM) */
    
    {
#if !defined(DAGUE_DRY_RUN)
    CORE_zgemm(PlasmaConjTrans, PlasmaNoTrans,
               descA.mb, tempnn, descA.nb,
               (dague_complex64_t)-1.0, A /*A(k, m)*/, ldak,
                                        B /*A(k, n)*/, ldak,
               (dague_complex64_t) 1.0, C /*A(m, n)*/, ldam);
#endif  /* !defined(DAGUE_DRY_RUN) */
    }

    printlog("CORE_zgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %e, A(%d,%d)[%p], %d, A(%d,%d)[%p], %d, %e, A(%d,%d)[%p], %d)\n",
             k, m, n,
             plasma_const( PlasmaConjTrans ),  plasma_const( PlasmaNoTrans ),
             descA.mb, tempnn, descA.nb,
             -1.0, k, m, A, ldak,
                   k, n, B, ldak,
              1.0, m, n, C, ldam);
}
END
